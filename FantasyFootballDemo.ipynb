{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptZ7E7Ki3ork"
      },
      "source": [
        "## Predicting Fantasy Football Draftability Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_u7DrxJ3bqk"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzAfntGjKPbD",
        "outputId": "44bf14c6-d4e3-4cd4-ab3e-74c8d46ba4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries have been imported successfully...\n"
          ]
        }
      ],
      "source": [
        "# Rerun this code cell until all libraries are imported successfully\n",
        "try:\n",
        "  import gradio as gr   # https://www.gradio.app/docs\n",
        "  import pandas as pd   # https://pandas.pydata.org/docs/\n",
        "  import numpy as np   # https://numpy.org/doc/\n",
        "  from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer   # https://scikit-learn.org/stable/modules/preprocessing.html\n",
        "  import pickle   # https://docs.python.org/3/library/pickle.html\n",
        "  print(\"All libraries have been imported successfully...\")\n",
        "except:\n",
        "  !pip install gradio\n",
        "  !pip install pandas\n",
        "  !pip install numpy\n",
        "  !pip install scikit-learn\n",
        "  !pip install pickle\n",
        "  print(\"Some libraries are not found, installing...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdRHCtoE3hN5"
      },
      "source": [
        "# Creating the demos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dds6nBHmqAeC"
      },
      "source": [
        "## Demo using manual inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "LAA6l920SvTH",
        "outputId": "089965c6-c22d-4915-8cd5-ab7093420416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://98c4a2958d2b38c369.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://98c4a2958d2b38c369.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Load the pre-trained model\n",
        "with open(\"Random_Forest.pkl\", \"rb\") as model_file:\n",
        "  best_model = pickle.load(model_file)\n",
        "\n",
        "# Define numerical and position columns\n",
        "numerical_columns = [\"Age\", \"G\", \"GS\", \"Cmp\", \"Att\", \"Yds\", \"TD\", \"Int\",\n",
        "                     \"RushAtt\", \"RushYds\", \"YA\", \"RushTD\", \"Tgt\", \"Rec\",\n",
        "                     \"RecYds\", \"YR\", \"RecTD\", \"Fmb\", \"FL\", \"PPR\"]\n",
        "name_columns = [\"Age\", \"G - Games Played\", \"GS - Games Started\", \"Cmp - Completed Passes\", \"Att - Attempts\", \"Yds - Total Yards\", \"TD - Touchdowns\", \"Int - Interceptions\",\n",
        "                     \"RushAtt - Rushing Attempts\", \"RushYds - Rushing Yards\", \"YA - Yards After Catch\", \"RushTD - Rushing Touchdowns\", \"Tgt - Targets\", \"Rec - Receptions\",\n",
        "                     \"RecYds - Receiving Yards\", \"YR - Yards per Reception\", \"RecTD - Receiving Touchdowns\", \"Fmb - Fumbles\", \"FL - Fumbles Lost\", \"PPR - Points per Reception\"]\n",
        "positions = [\"Quarterback\", \"Running Back\", \"Tight End\", \"Wide Receiver\"]\n",
        "encoded_positions = [f\"FantPos_{pos}\" for pos in positions]  # [\"FantPos_QB\", \"FantPos_RB\", ...]\n",
        "\n",
        "# Fit preprocessors\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False).fit(np.array(positions).reshape(-1, 1))\n",
        "\n",
        "# Prediction function\n",
        "def predict_fantasy(*inputs):\n",
        "  # Replacing all empty values with 0 or a default value\n",
        "  full_inputs = [0 if x is None else x for x in inputs[:-1]]\n",
        "  if inputs[-1] is None:\n",
        "    full_inputs.append(\"QB\")\n",
        "  else:\n",
        "    full_inputs.append(inputs[-1])\n",
        "  inputs = full_inputs\n",
        "\n",
        "  try:\n",
        "    # Separate numerical inputs and position\n",
        "    numerical_inputs = np.array(inputs[:-1]).reshape(1, -1)\n",
        "    position_input = inputs[-1]\n",
        "\n",
        "    # Encode position as \"FantPos_*\"\n",
        "    position_encoded = np.zeros(len(encoded_positions))\n",
        "    position_encoded[positions.index(position_input)] = 1\n",
        "    position_encoded = position_encoded.reshape(1, -1)  # Ensure it's 2D\n",
        "\n",
        "    # Combine scaled numerical inputs and encoded position\n",
        "    combined_inputs = np.hstack([numerical_inputs, position_encoded])\n",
        "\n",
        "    # Predict using the model\n",
        "    prediction = best_model.predict(combined_inputs)\n",
        "    print(combined_inputs)\n",
        "    return prediction[0]\n",
        "  except Exception as e:\n",
        "    return f\"Error: {str(e)}\"\n",
        "\n",
        "# Gradio Interface\n",
        "feature_inputs = [gr.Number(label=namecol) for col, namecol in zip(numerical_columns, name_columns)] + [gr.Dropdown(choices=positions, label=\"Position\")]\n",
        "demo = gr.Interface(fn=predict_fantasy,\n",
        "                    inputs=feature_inputs,\n",
        "                    outputs=[gr.Number(label=\"Position Ranking\")],\n",
        "                    title=\"Fantasy Football Rank Predictor\",\n",
        "                    description=\"Provide key player stats and position to predict their positional rank.\")\n",
        "\n",
        "# Launch the Gradio demo\n",
        "demo.launch(debug=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV2tU53OqFWa"
      },
      "source": [
        "## Demo using sliders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "Gmd6382JnDI8",
        "outputId": "3903cc96-6be2-41b6-835d-8cc40fb235e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://84f6e2bd19d55bc4ea.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://84f6e2bd19d55bc4ea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Load the pre-trained model\n",
        "with open(\"Random_Forest.pkl\", \"rb\") as model_file:\n",
        "  best_model = pickle.load(model_file)\n",
        "\n",
        "# Define numerical and position columns\n",
        "numerical_columns = [\"Age\", \"G\", \"GS\", \"Cmp\", \"Att\", \"Yds\", \"TD\", \"Int\",\n",
        "                     \"RushAtt\", \"RushYds\", \"YA\", \"RushTD\", \"Tgt\", \"Rec\",\n",
        "                     \"RecYds\", \"YR\", \"RecTD\", \"Fmb\", \"FL\", \"PPR\"]\n",
        "name_columns = [\"Age\", \"G - Games Played\", \"GS - Games Started\", \"Cmp - Completed Passes\", \"Att - Attempts\", \"Yds - Total Yards\", \"TD - Touchdowns\", \"Int - Interceptions\",\n",
        "                     \"RushAtt - Rushing Attempts\", \"RushYds - Rushing Yards\", \"YA - Yards per Attempt\", \"RushTD - Rushing Touchdowns\", \"Tgt - Targets\", \"Rec - Receptions\",\n",
        "                     \"RecYds - Receiving Yards\", \"YR - Yards per Reception\", \"RecTD - Receiving Touchdowns\", \"Fmb - Fumbles\", \"FL - Fumbles Lost\", \"PPR - Points per Reception\"]\n",
        "positions = [\"Quarterback\", \"Running Back\", \"Tight End\", \"Wide Receiver\"]\n",
        "encoded_positions = [f\"FantPos_{pos}\" for pos in positions]  # [\"FantPos_QB\", \"FantPos_RB\", ...]\n",
        "\n",
        "# Fit preprocessors\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False).fit(np.array(positions).reshape(-1, 1))\n",
        "\n",
        "# Prediction function\n",
        "def predict_fantasy(*inputs):\n",
        "  print(inputs)\n",
        "  # Replacing all empty values with 0 or a default value\n",
        "  full_inputs = [0 if x is None else x for x in inputs[:-1]]\n",
        "  if inputs[-1] is None:\n",
        "    full_inputs.append(\"QB\")\n",
        "  else:\n",
        "    full_inputs.append(inputs[-1])\n",
        "  inputs = full_inputs\n",
        "\n",
        "  try:\n",
        "    # Separate numerical inputs and position\n",
        "    numerical_inputs = np.array(inputs[:-1]).reshape(1, -1)\n",
        "    position_input = inputs[-1]\n",
        "\n",
        "    # Encode position as \"FantPos_*\"\n",
        "    position_encoded = np.zeros(len(encoded_positions))\n",
        "    position_encoded[positions.index(position_input)] = 1\n",
        "    position_encoded = position_encoded.reshape(1, -1)  # Ensure it's 2D\n",
        "\n",
        "    # Combine scaled numerical inputs and encoded position\n",
        "    combined_inputs = np.hstack([numerical_inputs, position_encoded])\n",
        "\n",
        "    # Predict using the model\n",
        "    prediction = best_model.predict(combined_inputs)\n",
        "    print(combined_inputs)\n",
        "    return prediction[0]\n",
        "  except Exception as e:\n",
        "    return f\"Error: {str(e)}\"\n",
        "\n",
        "data_df = pd.read_csv(\"Fantasy_Football_Stats.csv\", encoding='latin-1')\n",
        "\n",
        "# Gradio Interface\n",
        "feature_inputs = [gr.Slider(0, (((data_df[col].max() + 99) // 100) * 100), step=1, label=namecol, interactive=True) for col, namecol in zip(numerical_columns, name_columns)] + [gr.Dropdown(choices=positions, label=\"Position\")]\n",
        "demo = gr.Interface(fn=predict_fantasy,\n",
        "                    inputs=feature_inputs,\n",
        "                    outputs=[gr.Number(label=\"Position Ranking\")],\n",
        "                    title=\"Fantasy Football Rank Predictor\",\n",
        "                    description=\"Provide key player stats and position to predict their positional rank.\")\n",
        "\n",
        "# Launch the Gradio demo\n",
        "demo.launch(debug=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}